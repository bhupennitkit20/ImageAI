{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FNYR_ZcZuKGY8n_ma5wIALcuxUMsu7Ff",
      "authorship_tag": "ABX9TyPB9qXJWKpLUWJdfGBxoXK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhupennitkit20/ImageAI/blob/master/Copy_of_Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ9BOUCRWU18",
        "colab_type": "code",
        "outputId": "42f1f32d-409b-4d39-a70c-a2d0a8aed10c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "# %matplotlib inline\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "\n",
        "data = pd.read_csv(\"/content/mapping.csv\")\n",
        "test = pd.read_csv('/content/testing.csv')\n",
        "\n",
        "X = []\n",
        "for img_name in data.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X.append(img)\n",
        "X = np.array(X)\n",
        "\n",
        "test_image = []\n",
        "for img_name in test.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    test_image.append(img)\n",
        "test_img = np.array(test_image)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "train_y = np_utils.to_categorical(data.Class)\n",
        "test_y = np_utils.to_categorical(test.Class)\n",
        "\n",
        "image = []\n",
        "for i in range(0,X.shape[0]):\n",
        "    a = resize(X[i], preserve_range=True, output_shape=(224,224,3)).astype(int)\n",
        "    image.append(a)\n",
        "X = np.array(image)\n",
        "\n",
        "test_image = []\n",
        "for i in range(0,test_img.shape[0]):\n",
        "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
        "    test_image.append(a)\n",
        "test_image = np.array(test_image)\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "X = preprocess_input(X, mode='tf')\n",
        "test_image = preprocess_input(test_image, mode='tf')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, train_y, test_size=0.3, random_state=42)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "X_train = base_model.predict(X_train)\n",
        "X_valid = base_model.predict(X_valid)\n",
        "test_image = base_model.predict(test_image)\n",
        "\n",
        "X_train = X_train.reshape(155, 7*7*512)\n",
        "X_valid = X_valid.reshape(67, 7*7*512)\n",
        "test_image = test_image.reshape(36, 7*7*512)\n",
        "\n",
        "train = X_train/X_train.max()\n",
        "X_valid = X_valid/X_train.max()\n",
        "test_image = test_image/test_image.max()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(InputLayer((7*7*512,)))    # input layer\n",
        "model.add(Dense(units=1024, activation='sigmoid'))   # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=512, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=256, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(3, activation='softmax'))            # output layer\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "class_weights = compute_class_weight('balanced',np.unique(data.Class), data.Class)  # computing weights of different classes\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]      # model check pointing based on validation loss\n",
        "\n",
        "model.fit(train, y_train, epochs=10, validation_data=(X_valid, y_valid), class_weight=class_weights, callbacks=callbacks_list)\n",
        "\n",
        "model.load_weights(\"weights.best.hdf5\")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "scores = model.evaluate(test_image, test_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 155 samples, validate on 67 samples\n",
            "Epoch 1/10\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 1.3905 - accuracy: 0.3742 - val_loss: 1.0091 - val_accuracy: 0.5373\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.00907, saving model to weights.best.hdf5\n",
            "Epoch 2/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 1.0338 - accuracy: 0.5226 - val_loss: 0.8895 - val_accuracy: 0.7015\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.00907 to 0.88951, saving model to weights.best.hdf5\n",
            "Epoch 3/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 1.1049 - accuracy: 0.3742 - val_loss: 0.7938 - val_accuracy: 0.5373\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.88951 to 0.79382, saving model to weights.best.hdf5\n",
            "Epoch 4/10\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.9457 - accuracy: 0.5871 - val_loss: 0.7136 - val_accuracy: 0.5373\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.79382 to 0.71360, saving model to weights.best.hdf5\n",
            "Epoch 5/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.7545 - accuracy: 0.7032 - val_loss: 0.5167 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.71360 to 0.51666, saving model to weights.best.hdf5\n",
            "Epoch 6/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5422 - accuracy: 0.8129 - val_loss: 0.2851 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.51666 to 0.28506, saving model to weights.best.hdf5\n",
            "Epoch 7/10\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.3280 - accuracy: 0.9290 - val_loss: 0.1513 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.28506 to 0.15134, saving model to weights.best.hdf5\n",
            "Epoch 8/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.1694 - accuracy: 0.9806 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.15134 to 0.07042, saving model to weights.best.hdf5\n",
            "Epoch 9/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0799 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.07042 to 0.03757, saving model to weights.best.hdf5\n",
            "Epoch 10/10\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.03757 to 0.01666, saving model to weights.best.hdf5\n",
            "36/36 [==============================] - 0s 3ms/step\n",
            "accuracy: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA9hESEej5sa",
        "colab_type": "code",
        "outputId": "4fc8d01a-cda1-4531-9692-376fa12f684c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        }
      },
      "source": [
        "import cv2     # for capturing videos\n",
        "import math   # for mathematical operations\n",
        "import matplotlib.pyplot as plt    # for plotting the images\n",
        "# %matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image   # for preprocessing the images\n",
        "import numpy as np    # for mathematical operations\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize   # for resizing images\n",
        "\n",
        "\n",
        "data = pd.read_csv('/content/mapping.csv')\n",
        "\n",
        "'''# show a image\n",
        "img = plt.imread('frame0.jpg')   # reading image using its name\n",
        "plt.imshow(img)\n",
        "\n",
        "# Print data of the csv file\n",
        "data = pd.read_csv('mapping.csv')     # reading the csv file\n",
        "data.head()      # printing first five rows of the file'''\n",
        "\n",
        "\n",
        "X = [ ]     # creating an empty array\n",
        "for img_name in data.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X.append(img)  # storing each image in array X\n",
        "X = np.array(X)    # converting list to array\n",
        "\n",
        "\n",
        "y = data.Class\n",
        "dummy_y = np_utils.to_categorical(y)    # one hot encoding Classes\n",
        "\n",
        "\n",
        "image = []\n",
        "for i in range(0,X.shape[0]):\n",
        "    a = resize(X[i], preserve_range=True, output_shape=(224,224)).astype(int)      # reshaping to 224*224*3\n",
        "    image.append(a)\n",
        "X = np.array(image)\n",
        "\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "X = preprocess_input(X, mode='tf')      # preprocessing the input data\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, dummy_y, test_size=0.3, random_state=42)    # preparing the validation set\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout\n",
        "\n",
        "\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))    # include_top=False to remove the top layer\n",
        "\n",
        "\n",
        "X_train = base_model.predict(X_train)\n",
        "X_valid = base_model.predict(X_valid)\n",
        "X_train.shape, X_valid.shape\n",
        "\n",
        "X_train = X_train.reshape(155, 7*7*512)      # converting to 1-D\n",
        "X_valid = X_valid.reshape(67, 7*7*512)\n",
        "\n",
        "train = X_train/X_train.max()      # centering the data\n",
        "X_valid = X_valid/X_train.max()\n",
        "\n",
        "\n",
        "# i. Building the model\n",
        "model = Sequential()\n",
        "model.add(InputLayer((7*7*512,)))    # input layer\n",
        "model.add(Dense(units=1024, activation='sigmoid')) # hidden layer\n",
        "model.add(Dense(3, activation='softmax'))    # output layer\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# ii. Compiling the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# iii. Training the model\n",
        "model.fit(train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
        "\n",
        "test = pd.read_csv('test.csv')\n",
        "test_image = []\n",
        "for img_name in test.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    test_image.append(img)\n",
        "test_img = np.array(test_image)\n",
        "test_image = []\n",
        "for i in range(0,test_img.shape[0]):\n",
        "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
        "    test_image.append(a)\n",
        "test_image = np.array(test_image)\n",
        "\n",
        "# preprocessing the images\n",
        "test_image = preprocess_input(test_image, mode='tf')\n",
        "\n",
        "# extracting features from the images using pretrained model\n",
        "test_image = base_model.predict(test_image)\n",
        "\n",
        "# converting the images to 1-D form\n",
        "test_image = test_image.reshape(36, 7*7*512)\n",
        "\n",
        "# zero centered images\n",
        "test_image = test_image/test_image.max()\n",
        "\n",
        "predictions = model.predict_classes(test_image)\n",
        "\n",
        "print(\"No of appearances of both is\", predictions[predictions==2].shape[0], \"times\")\n",
        "print(\"No of appearances of Dog is\", predictions[predictions==0].shape[0], \"times\")\n",
        "print(\"No of appearances of Human is\", predictions[predictions==1].shape[0], \"times\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 25,694,211\n",
            "Trainable params: 25,694,211\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 155 samples, validate on 67 samples\n",
            "Epoch 1/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.8286 - accuracy: 0.6387 - val_loss: 0.2304 - val_accuracy: 0.9254\n",
            "Epoch 2/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.1688 - accuracy: 0.9419 - val_loss: 0.1262 - val_accuracy: 0.9851\n",
            "Epoch 3/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.3971e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 6.4205e-04 - accuracy: 1.0000 - val_loss: 6.4977e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 4.9786e-04 - accuracy: 1.0000 - val_loss: 6.2651e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 4.4776e-04 - accuracy: 1.0000 - val_loss: 6.2171e-04 - val_accuracy: 1.0000\n",
            "No of appearances of both is 13 times\n",
            "No of appearances of Dog is 9 times\n",
            "No of appearances of Human is 14 times\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-rvm_krMpmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c99EvWo1s9-x",
        "colab_type": "code",
        "outputId": "66b86be9-087a-4c56-d359-146691c190b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SJ1YIPEM1L7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4SJ-tGNkOeY",
        "colab_type": "code",
        "outputId": "b39b8e46-b45a-40f0-ce46-9316904e8d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "\n",
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "07_structured_data.ipynb\t   Sample Excel file.xlsx\n",
            "BigQuery recipes\t\t   script.ipynb\n",
            "Colab Notebooks\t\t\t   TFGan tutorial in Colab.txt\n",
            "Copy of nima colab.ipynb\t   to_upload (1).ipynb\n",
            "created.txt\t\t\t   to_upload (2).ipynb\n",
            "Exported DataFrame sheet.gsheet    to_upload (3).ipynb\n",
            "foo.txt\t\t\t\t   to_upload.ipynb\n",
            "Pickle + Drive FUSE example.ipynb  variables.pickle\n",
            "Sample Excel file.gsheet\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}